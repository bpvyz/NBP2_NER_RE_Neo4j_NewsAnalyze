import os
import re
import json
import time
import asyncio
from typing import Optional, Dict, Any

from dotenv import load_dotenv
from openai import AsyncOpenAI
from tqdm.asyncio import tqdm_asyncio
from colorama import Fore, init

# Inicijalizacija okru≈æenja
load_dotenv()
init(autoreset=True)

# Inicijalizacija asinhronog OpenAI klijenta
client = AsyncOpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv("OPENROUTER_API_KEY")
)

# Konstantna putanja do podataka
DATA_PATH = "data/serbian_news_articles.json"
OUTPUT_PATH = "data/entities_and_relations.json"
AI_MODEL = "google/gemini-2.0-flash-001"

# Uƒçitaj vesti
def load_articles(path: str) -> list[dict]:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def build_prompt(title, text: str) -> str:
    return f"""
Izvuci entitete (Osoba, Organizacija, Lokacija, Vreme, Aktivnost, AktivnostDogaƒëaj, Dogaƒëaj, Grupa, Vozilo, Proizvod, Umetniƒçko delo, Dokument, Biljka, Broj, Hrana, Piƒáe, Institucija, Simbol, HranaPiƒáe, ≈Ωivotinja, Tehnologija) 
i deskriptivne relacije (dogaƒëaji, akcije, interakcije) iz sledeƒáeg teksta vesti, koristeƒái odgovarajuƒáe tipove za Neo4j.

Relacije moraju biti konkretne, jasno definisane izmeƒëu entiteta. Svaki entitet mora biti oznaƒçen jednom od dozvoljenih labela.

**Zatim dodatno:**

1. Sa≈æmi najva≈ænije proverljive informacije iz teksta.  
   Zatim za svaku proceni njenu verodostojnost koristeƒái sledeƒáe kriterijume:
   - **taƒçno** ‚Äî u skladu sa poznatim ƒçinjenicama ili jasno potkrepljeno izvorima u tekstu,
   - **verovatno taƒçno** ‚Äî deluje taƒçno i logiƒçno na osnovu informacija u tekstu, ali bez dodatnih dokaza,
   - **sumnjivo** ‚Äî neobiƒçno, nejasno, bez izvora ili sa moguƒáim manipulativnim jezikom,
   - **nepotkrepljeno** ‚Äî tvrdnja bez ikakvih naznaka dokaza ili konteksta.

   Ako je moguƒáe, daj **kratak dodatni kontekst** koji ukljuƒçuje:
   - istorijski, pravni, dru≈°tveni ili institucionalni okvir,
   - poznate ƒçinjenice u javnosti (npr. poznate presude, zakoni, prethodni sluƒçajevi, izjave relevantnih institucija).

2. Opi≈°i **ton** teksta ‚Äî uzimajuƒái u obzir reƒçnik, stil pisanja i emocije koje prenosi (neutralan, informativan, pristrasan, senzacionalistiƒçki, emotivan, manipulativan, pozitivan, negativan)

Tekst vesti:
{title}

{text}

Odgovor u taƒçno sledeƒáem formatu:
Entiteti: [entitet1:label, entitet2:label, entitet3:label]
Relacije: [entitet1 -[:relacija]-> entitet2, entitet3 -[:relacija]-> entitet4]
FactCheck: 
- Tvrdnja 1: "<iz teksta>"
  Ocena: taƒçno / verovatno taƒçno / sumnjivo / nepotkrepljeno
  Kontekst: <kratko obja≈°njenje ili referenca na poznate ƒçinjenice>

- Tvrdnja 2: "..."
  ...

Ton: <kratka analiza tona>
"""

async def extract_entities_and_relations(title, text: str) -> str:

    response = await client.chat.completions.create(
        model=AI_MODEL,
        messages=[{"role": "user", "content": build_prompt(title, text)}],
        temperature=0.2
    )
    return response.choices[0].message.content.strip()

def extract_matches(text: str) -> tuple[str, str]:
    entities_match = re.search(r'Entiteti: \[(.*?)\]', text)
    relations_match = re.search(r'Relacije: \[(.*]?)\]', text)

    entities = entities_match.group(1).strip() if entities_match else ""
    relations = relations_match.group(1).strip() if relations_match else ""

    return entities, relations

async def process_article(article: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    title = article.get("title", "")
    text = article.get("text", "")
    if not text:
        return None

    try:
        result = await extract_entities_and_relations(title, text)
        entities, relations = extract_matches(result)

        factcheck_match = re.search(r'(?s)FactCheck:\s*(.*?)Ton:', result)
        tone_match = re.search(r'Ton:\s*(.*)', result)

        factcheck = factcheck_match.group(1).strip() if factcheck_match else ""
        tone = tone_match.group(1).strip() if tone_match else ""

        return {
            "article_source": article.get("source"),
            "article_bias": article.get("bias"),
            "article_title": article.get("title"),
            "article_url": article.get("url"),
            "article_text": text,
            "entities_and_relations": result,
            "entities": entities,
            "entity_count": len(entities.split(", ")) if entities else 0,
            "relations": relations,
            "relations_count": len(relations.split(", ")) if relations else 0,
            "fact_check": factcheck,
            "tone_analysis": tone
        }


    except Exception as e:
        print(Fore.RED + f"[‚úñ] Gre≈°ka za ƒçlanak '{article.get('title', 'N/A')}': {e}")
        return None

async def process_articles():
    articles = load_articles(DATA_PATH)

    print(Fore.CYAN + f"üîé Analiza {len(articles)} ƒçlanaka...\n")
    results = await tqdm_asyncio.gather(
        *(process_article(article) for article in articles),
        desc="üîç Obrada vesti",
        total=len(articles),
        colour='blue',
        leave=False,
        unit="article",
        unit_scale=True,
        smoothing=0.1,
        miniters=1,
        bar_format="{l_bar}{bar}| {n}/{total} [{elapsed}<{remaining}, {rate_fmt}]",
    )

    cleaned_results = [r for r in results if r]
    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        json.dump(cleaned_results, f, ensure_ascii=False, indent=4)

    print(Fore.GREEN + f"\n‚úî Saƒçuvano {len(cleaned_results)} ƒçlanaka u '{OUTPUT_PATH}'")

if __name__ == "__main__":
    start = time.time()
    print(Fore.MAGENTA + f"\nKoristim {AI_MODEL} model za analizu!\n")
    asyncio.run(process_articles())
    print(Fore.YELLOW + f"\n‚è± Ukupno vreme: {time.time() - start:.2f} sekundi")